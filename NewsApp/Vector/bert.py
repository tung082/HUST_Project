import numpy as np
import pandas as pd
from pymongo import MongoClient
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin
from sentence_transformers import SentenceTransformer
from bson.objectid import ObjectId

# ğŸ”¹ Káº¿t ná»‘i MongoDB
client = MongoClient("mongodb://localhost:27017/")
db = client.news_raw
collection = db.dantri
articles = list(collection.find())

if not articles:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u trong MongoDB!")
    exit()

df = pd.DataFrame(articles)

# ğŸ”¹ Chuyá»ƒn ObjectId thÃ nh string
df["_id"] = df["_id"].astype(str)

# ğŸ”¹ Xá»­ lÃ½ giÃ¡ trá»‹ None (náº¿u cÃ³)
df["title"] = df["title"].fillna("")
df["content"] = df["content"].fillna("")
df["author"] = df["author"].fillna("")

# ğŸ”¹ Äá»‹nh nghÄ©a token Ä‘áº·c biá»‡t
TITLE_TOKEN = "<|title|>"
TITLE_END_TOKEN = "<|/title|>"
CONTENT_TOKEN = "<|content|>"
CONTENT_END_TOKEN = "<|/content|>"
AUTHOR_TOKEN = "<|author|>"
AUTHOR_END_TOKEN = "<|/author|>"

# ğŸ”¹ Káº¿t há»£p cÃ¡c trÆ°á»ng dá»¯ liá»‡u vá»›i token Ä‘áº·c biá»‡t
df["combined_text"] = (
    TITLE_TOKEN + df["title"] + TITLE_END_TOKEN + " " +
    CONTENT_TOKEN + df["content"] + CONTENT_END_TOKEN + " " +
    AUTHOR_TOKEN + df["author"] + AUTHOR_END_TOKEN
)

# ğŸ”¹ Load mÃ´ hÃ¬nh BERT (SBERT)
bert_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

# ğŸ”¹ Transformer Ä‘á»ƒ chuyá»ƒn vÄƒn báº£n thÃ nh vector báº±ng BERT
class BERTEmbedding(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        return np.array([bert_model.encode(text) for text in X])  # Chuyá»ƒn thÃ nh vector

# ğŸ”¹ Pipeline xá»­ lÃ½ dá»¯ liá»‡u káº¿t há»£p vá»›i token Ä‘áº·c biá»‡t
bert_pipeline = Pipeline([
    ('bert_embedding', BERTEmbedding())
])

# ğŸ”¹ Táº¡o vector BERT tá»« dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a
X = bert_pipeline.fit_transform(df["combined_text"])
print("âœ… ÄÃ£ tÃ­nh xong BERT Embeddings")

# ğŸ”¹ LÆ°u vector BERT vÃ o MongoDB
vector_collection = db.news_vector
vector_collection.delete_many({})  # XÃ³a dá»¯ liá»‡u cÅ© náº¿u cÃ³

# ğŸ”¹ Chuyá»ƒn dá»¯ liá»‡u sang dictionary
bert_dict = {df["_id"][i]: X[i].tolist() for i in range(len(df))}

vector_data = []
for _id, vec in bert_dict.items():
    try:
        object_id = ObjectId(_id)
        vector_data.append({"_id": object_id, "vector_bert": vec})
    except Exception as e:
        print(f"âŒ Lá»—i khi chuyá»ƒn ObjectId {_id}: {e}")

if vector_data:
    vector_collection.insert_many(vector_data)
    print("âœ… BERT vectors Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o MongoDB!")
else:
    print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u há»£p lá»‡ Ä‘á»ƒ lÆ°u!")
